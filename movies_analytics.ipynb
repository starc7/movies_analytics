{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Movie-analytics').getOrCreate()\n",
        "\n",
        "movies_rdd = spark.sparkContext.textFile('./movie_lens/movies.dat')\n",
        "ratings_rdd = spark.sparkContext.textFile('./movie_lens/ratings.dat')\n"
      ],
      "metadata": {
        "id": "Yf5JWqYJ62HY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB5xqW176Iph",
        "outputId": "13252e10-2c71-4035-f6fd-a26db4fae8ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **All RDD operations**"
      ],
      "metadata": {
        "id": "y7prEse8pAMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Distinct genre in dataset of movies**"
      ],
      "metadata": {
        "id": "V8fXBTod8Gpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre = movies_rdd.map(lambda line: line.split(\"::\")[2])\n",
        "testing = genre.flatMap(lambda line: line.split('|'))\n",
        "genres_distinct_sorted = testing.distinct().sortBy(lambda x: x[0])\n",
        "genres_distinct_sorted.coalesce(1).saveAsTextFile('./results/spark_rdd_results/distinct_genre')"
      ],
      "metadata": {
        "id": "nuunY1A57qYO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Latest released movies**"
      ],
      "metadata": {
        "id": "XFzPb8tRC1K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_name = movies_rdd.map(lambda line: line.split(\"::\")[1])\n",
        "year = movie_name.map(lambda line: line[line.rfind(\"(\") + 1:line.rfind(\")\")])\n",
        "latest = year.max()\n",
        "latest_movies = movie_name.filter(lambda line: \"(\" + latest + \")\" in line)\n",
        "latest_movies.coalesce(1).saveAsTextFile('./results/spark_rdd_results/latest_movies')"
      ],
      "metadata": {
        "id": "Xh2XXhsfC94r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Number of movies in each genre**"
      ],
      "metadata": {
        "id": "T7xpTirlFSCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flat_genre = genre.flatMap(lambda lines: lines.split(\"\\\\|\"))\n",
        "genre_kv = flat_genre.map(lambda k: (k, 1))\n",
        "genre_count = genre_kv.reduceByKey(lambda k, v: (k + v))\n",
        "genre_sort = genre_count.sortByKey()\n",
        "genre_sort.coalesce(1).saveAsTextFile('./results/spark_rdd_results/no_of_movies_in_each_genre')"
      ],
      "metadata": {
        "id": "DlEUkIVKF1gC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Top 10 most watched movies**"
      ],
      "metadata": {
        "id": "khuCrKtWIopA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = ratings_rdd.map(lambda line: int(line.split(\"::\")[1]))\n",
        "movies_pair = movies.map(lambda mv: (mv, 1))\n",
        "movies_count = movies_pair.reduceByKey(lambda x, y: x + y)\n",
        "movies_sorted = movies_count.sortBy(lambda x: x[1], ascending=False, numPartitions=1)\n",
        "mv_top10_list = movies_sorted.take(10)\n",
        "mv_top10_rdd = spark.sparkContext.parallelize(mv_top10_list)\n",
        "movie_names = spark.sparkContext.textFile(\"./movie_lens/movies.dat\") \\\n",
        "    .map(lambda line: (int(line.split(\"::\")[0]), line.split(\"::\")[1]))\n",
        "join_output = movie_names.join(mv_top10_rdd)\n",
        "result = join_output.sortBy(lambda x: x[1][1], ascending=False) \\\n",
        "    .map(lambda x: f\"{x[0]},{x[1][0]},{x[1][1]}\") \\\n",
        "    .coalesce(1).saveAsTextFile(\"./results/spark_rdd_results/Top-10-CSV\")"
      ],
      "metadata": {
        "id": "GiJIUUAtJuPQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Movies starting with each letter**"
      ],
      "metadata": {
        "id": "oGudhWpTSTAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = movies_rdd.map(lambda lines: lines.split(\"::\")[1])\n",
        "string_flat = movies.map(lambda lines: lines.split(\" \")[0])\n",
        "movies_letter = string_flat.filter(lambda word: word[0].isalpha()).map(lambda word: (word[0].upper(), 1))\n",
        "movies_letter_count = movies_letter.reduceByKey(lambda k, v: (k + v)).sortByKey()\n",
        "movies_digit = string_flat.filter(lambda word: word[0].isdigit()).map(lambda word: (word[0], 1))\n",
        "movies_digit_count = movies_digit.reduceByKey(lambda k, v: k + v).sortByKey()\n",
        "result = movies_digit_count.union(movies_letter_count)\n",
        "result.coalesce(1).saveAsTextFile(\"./results/spark_rdd_results/Each-letter\")"
      ],
      "metadata": {
        "id": "arsxPTFKSU7P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **All dataframe operations**"
      ],
      "metadata": {
        "id": "rZZTEGYtUL-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Movies dataFrame**"
      ],
      "metadata": {
        "id": "t6ysRMm7VB1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ShortType\n",
        "from pyspark.sql.functions import row_number,lit, col\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "w = Window().orderBy(lit('A'))\n",
        "\n",
        "id_schema = StructType([StructField(\"MovieID\", StringType(), True)])\n",
        "title_schema = StructType([StructField(\"Title\", StringType(), True)])\n",
        "year_schema = StructType([StructField(\"Year\", StringType(), True)])\n",
        "genre_schema = StructType([StructField(\"Genre\", StringType(), True)])\n",
        "\n",
        "movie_details_rdd = movies_rdd.map(lambda line: line.split(\"::\"))\n",
        "\n",
        "movie_id_rdd = movie_details_rdd.map(lambda n: (n[0],))\n",
        "movie_id_df = movie_id_rdd.toDF(schema=id_schema)\n",
        "\n",
        "movie_title_rdd = movie_details_rdd.map(lambda n: (n[1][:n[1].rfind(' (')],))\n",
        "movie_title_df = movie_title_rdd.toDF(schema=title_schema)\n",
        "\n",
        "movie_year_rdd = movie_details_rdd.map(lambda n: (n[1][n[1].rfind('(')+1:n[1].rfind(')')],))\n",
        "movie_year_df = movie_year_rdd.toDF(schema=year_schema)\n",
        "\n",
        "movie_genre_rdd = movie_details_rdd.map(lambda n: (n[2],))\n",
        "movie_genre_df = movie_genre_rdd.toDF(schema=genre_schema)\n",
        "\n",
        "movie_id_df = movie_id_df.withColumn('id', row_number().over(w))\n",
        "movie_title_df = movie_title_df.withColumn('id', row_number().over(w))\n",
        "movie_year_df = movie_year_df.withColumn('id', row_number().over(w))\n",
        "movie_genre_df = movie_genre_df.withColumn('id', row_number().over(w))\n",
        "\n",
        "result1 = movie_id_df.join(movie_title_df, on=['id'])\n",
        "result2 = result1.join(movie_year_df, on=['id'])\n",
        "movies_df = result2.join(movie_genre_df, on=['id']).drop('id')\n",
        "\n",
        "movies_df = movies_df.withColumn(\"Year\", col(\"Year\").cast(\"int\"))\n",
        "movies_df = movies_df.withColumn(\"MovieId\", col(\"MovieID\").cast(\"int\"))\n",
        "movies_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SQ5YdX_ZbUe",
        "outputId": "91124e4b-c857-4b4c-ef48-6de154373937"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+----+--------------------+\n",
            "|MovieId|               Title|Year|               Genre|\n",
            "+-------+--------------------+----+--------------------+\n",
            "|      1|           Toy Story|1995|Animation|Childre...|\n",
            "|      2|             Jumanji|1995|Adventure|Childre...|\n",
            "|      3|    Grumpier Old Men|1995|      Comedy|Romance|\n",
            "|      4|   Waiting to Exhale|1995|        Comedy|Drama|\n",
            "|      5|Father of the Bri...|1995|              Comedy|\n",
            "|      6|                Heat|1995|Action|Crime|Thri...|\n",
            "|      7|             Sabrina|1995|      Comedy|Romance|\n",
            "|      8|        Tom and Huck|1995|Adventure|Children's|\n",
            "|      9|        Sudden Death|1995|              Action|\n",
            "|     10|           GoldenEye|1995|Action|Adventure|...|\n",
            "|     11|American Presiden...|1995|Comedy|Drama|Romance|\n",
            "|     12|Dracula: Dead and...|1995|       Comedy|Horror|\n",
            "|     13|               Balto|1995|Animation|Children's|\n",
            "|     14|               Nixon|1995|               Drama|\n",
            "|     15|    Cutthroat Island|1995|Action|Adventure|...|\n",
            "|     16|              Casino|1995|      Drama|Thriller|\n",
            "|     17|Sense and Sensibi...|1995|       Drama|Romance|\n",
            "|     18|          Four Rooms|1995|            Thriller|\n",
            "|     19|Ace Ventura: When...|1995|              Comedy|\n",
            "|     20|         Money Train|1995|              Action|\n",
            "+-------+--------------------+----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ratings DataFrame**"
      ],
      "metadata": {
        "id": "MMCpGAe_ucwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"UserId\", StringType(), True),\n",
        "    StructField(\"MovieId\", StringType(), True),\n",
        "    StructField(\"Ratings\", StringType(), True),\n",
        "    StructField(\"Timestamp\", StringType(), True)\n",
        "])\n",
        "\n",
        "rowRDD = ratings_rdd.map(lambda line: line.split(\"::\")).map(lambda x: Row(x[0], x[1], x[2], x[3]))\n",
        "ratings_df = spark.createDataFrame(rowRDD, schema)\n",
        "ratings_df = ratings_df.withColumn(\"Ratings\", col(\"Ratings\").cast(\"int\"))\n",
        "\n",
        "ratings_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nexXs1R1ui6L",
        "outputId": "3df24dcb-8e52-4a8f-e358-47e31dfe155a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-------+---------+\n",
            "|UserId|MovieId|Ratings|Timestamp|\n",
            "+------+-------+-------+---------+\n",
            "|     1|   1193|      5|978300760|\n",
            "|     1|    661|      3|978302109|\n",
            "|     1|    914|      3|978301968|\n",
            "|     1|   3408|      4|978300275|\n",
            "|     1|   2355|      5|978824291|\n",
            "|     1|   1197|      3|978302268|\n",
            "|     1|   1287|      5|978302039|\n",
            "|     1|   2804|      5|978300719|\n",
            "|     1|    594|      4|978302268|\n",
            "|     1|    919|      4|978301368|\n",
            "|     1|    595|      5|978824268|\n",
            "|     1|    938|      4|978301752|\n",
            "|     1|   2398|      4|978302281|\n",
            "|     1|   2918|      4|978302124|\n",
            "|     1|   1035|      5|978301753|\n",
            "|     1|   2791|      4|978302188|\n",
            "|     1|   2687|      3|978824268|\n",
            "|     1|   2018|      4|978301777|\n",
            "|     1|   3105|      5|978301713|\n",
            "|     1|   2797|      4|978302039|\n",
            "+------+-------+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Users DataFrame**"
      ],
      "metadata": {
        "id": "nkPNtVvJ0vcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_rdd = spark.sparkContext.textFile('./movie_lens/users.dat')\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"UserId\", StringType(), True),\n",
        "    StructField(\"Gender\", StringType(), True),\n",
        "    StructField(\"Age\", StringType(), True),\n",
        "    StructField(\"Occupation\", StringType(), True),\n",
        "    StructField(\"ZipCode\", StringType(), True)\n",
        "])\n",
        "\n",
        "rowRDD2 = users_rdd.map(lambda line: line.split(\"::\")).map(lambda x: Row(x[0], x[1], x[2], x[3], x[4]))\n",
        "\n",
        "users_df = spark.createDataFrame(rowRDD2, schema)\n",
        "\n",
        "users_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pIbxTGL0zjz",
        "outputId": "cc4ba9fc-a180-4c9a-848b-e69c4153ba13"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+----------+-------+\n",
            "|UserId|Gender|Age|Occupation|ZipCode|\n",
            "+------+------+---+----------+-------+\n",
            "|     1|     F|  1|        10|  48067|\n",
            "|     2|     M| 56|        16|  70072|\n",
            "|     3|     M| 25|        15|  55117|\n",
            "|     4|     M| 45|         7|  02460|\n",
            "|     5|     M| 25|        20|  55455|\n",
            "|     6|     F| 50|         9|  55117|\n",
            "|     7|     M| 35|         1|  06810|\n",
            "|     8|     M| 25|        12|  11413|\n",
            "|     9|     M| 25|        17|  61614|\n",
            "|    10|     F| 35|         1|  95370|\n",
            "|    11|     F| 25|         1|  04093|\n",
            "|    12|     M| 25|        12|  32793|\n",
            "|    13|     M| 45|         1|  93304|\n",
            "|    14|     M| 35|         0|  60126|\n",
            "|    15|     M| 25|         7|  22903|\n",
            "|    16|     F| 35|         0|  20670|\n",
            "|    17|     M| 50|         1|  95350|\n",
            "|    18|     F| 18|         3|  95825|\n",
            "|    19|     M|  1|        10|  48073|\n",
            "|    20|     M| 25|        14|  55113|\n",
            "+------+------+---+----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Users detailed DataFrame**"
      ],
      "metadata": {
        "id": "AQlcVmKixR9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "occupations = {\n",
        "  \"0\":  \"other\",\n",
        "\t\"1\":  \"academic/educator\",\n",
        "\t\"2\":  \"artist\",\n",
        "\t\"3\":  \"clerical/admin\",\n",
        "\t\"4\":  \"college/grad student\",\n",
        "\t\"5\":  \"customer service\",\n",
        "\t\"6\":  \"doctor/health care\",\n",
        "\t\"7\":  \"executive/managerial\",\n",
        "\t\"8\":  \"farmer\",\n",
        "\t\"9\":  \"homemaker\",\n",
        "\t\"10\":  \"K-12 student\",\n",
        "\t\"11\":  \"lawyer\",\n",
        "\t\"12\":  \"programmer\",\n",
        "\t\"13\":  \"retired\",\n",
        "\t\"14\":  \"sales/marketing\",\n",
        "\t\"15\":  \"scientist\",\n",
        "\t\"16\":  \"self-employed\",\n",
        "\t\"17\":  \"technician/engineer\",\n",
        "\t\"18\":  \"tradesman/craftsman\",\n",
        "\t\"19\":  \"unemployed\",\n",
        "\t\"20\":  \"writer\"\n",
        "}\n",
        "\n",
        "detailed_users_df = users_df.rdd.map(lambda x: (x.UserId, x.Gender, x.Age, occupations[x.Occupation], x.ZipCode)).toDF(['UserId', 'Gender', 'Age', 'Occupation', 'ZipCode'])\n",
        "detailed_users_df.show()\n",
        "detailed_users_df.write.format('csv').option('header', 'true').save('./results/dataframe_results/detailed_users')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DrKz_jAxcqo",
        "outputId": "e6090f35-5f38-4340-ec50-0f1fdda69d80"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+---+--------------------+-------+\n",
            "|UserId|Gender|Age|          Occupation|ZipCode|\n",
            "+------+------+---+--------------------+-------+\n",
            "|     1|     F|  1|        K-12 student|  48067|\n",
            "|     2|     M| 56|       self-employed|  70072|\n",
            "|     3|     M| 25|           scientist|  55117|\n",
            "|     4|     M| 45|executive/managerial|  02460|\n",
            "|     5|     M| 25|              writer|  55455|\n",
            "|     6|     F| 50|           homemaker|  55117|\n",
            "|     7|     M| 35|   academic/educator|  06810|\n",
            "|     8|     M| 25|          programmer|  11413|\n",
            "|     9|     M| 25| technician/engineer|  61614|\n",
            "|    10|     F| 35|   academic/educator|  95370|\n",
            "|    11|     F| 25|   academic/educator|  04093|\n",
            "|    12|     M| 25|          programmer|  32793|\n",
            "|    13|     M| 45|   academic/educator|  93304|\n",
            "|    14|     M| 35|               other|  60126|\n",
            "|    15|     M| 25|executive/managerial|  22903|\n",
            "|    16|     F| 35|               other|  20670|\n",
            "|    17|     M| 50|   academic/educator|  95350|\n",
            "|    18|     F| 18|      clerical/admin|  95825|\n",
            "|    19|     M|  1|        K-12 student|  48073|\n",
            "|    20|     M| 25|     sales/marketing|  55113|\n",
            "+------+------+---+--------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spark SQL**"
      ],
      "metadata": {
        "id": "Dix_es7hwOKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Oldest Movies**"
      ],
      "metadata": {
        "id": "ipRZBklH0_ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.createOrReplaceTempView(\"movies_table\")\n",
        "\n",
        "oldest_movies = spark.sql(\"Select title, year from movies_table where year = (select min(year) from movies_table)\")\n",
        "\n",
        "oldest_movies.write.format(\"csv\").option(\"header\",\"true\").save(\"./results/spark_sql_results/oldest_movies\")"
      ],
      "metadata": {
        "id": "NOxKssUiwTtV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **No. of movies each year**"
      ],
      "metadata": {
        "id": "I98GCDia-qm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_each_year = spark.sql(\"Select distinct(year), count(year) as no_of_movies from movies_table group by year order by year\")\n",
        "movies_each_year.write.format(\"csv\").option(\"header\",\"true\").save(\"./results/spark_sql_results/movies_each_year\")"
      ],
      "metadata": {
        "id": "3qHxLB6Z-zKb"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}